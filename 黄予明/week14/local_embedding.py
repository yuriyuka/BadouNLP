"""
æœ¬åœ°Embeddingæ¨¡å‹ - æ— éœ€API Key
ä½¿ç”¨Sentence Transformersåº“çš„é¢„è®­ç»ƒæ¨¡å‹
"""

import numpy as np
from chromadb import Documents, EmbeddingFunction, Embeddings

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("éœ€è¦å®‰è£…sentence-transformers: pip install sentence-transformers")

class LocalEmbeddingFunction(EmbeddingFunction):
    """
    æœ¬åœ°Embeddingå‡½æ•°ï¼Œä½¿ç”¨Sentence Transformers
    ä¼˜ç‚¹ï¼š
    1. å®Œå…¨ç¦»çº¿è¿è¡Œï¼Œæ— éœ€API Key
    2. å…è´¹ä½¿ç”¨
    3. é€Ÿåº¦å¿«
    4. æ”¯æŒä¸­è‹±æ–‡
    """
    
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        """
        åˆå§‹åŒ–æœ¬åœ°embeddingæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œæ¨èé€‰é¡¹ï¼š
                - "all-MiniLM-L6-v2": è½»é‡çº§ï¼Œè‹±æ–‡ä¸ºä¸»ï¼Œ384ç»´ (æ¨è)
                - "paraphrase-multilingual-MiniLM-L12-v2": å¤šè¯­è¨€ï¼Œ384ç»´
                - "distiluse-base-multilingual-cased": å¤šè¯­è¨€ï¼Œ512ç»´
        """
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            raise ImportError("è¯·å®‰è£…sentence-transformers: pip install sentence-transformers")
        
        self.model_name = model_name
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ°embeddingæ¨¡å‹: {model_name}")
        
        try:
            self.model = SentenceTransformer(model_name)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ! å‘é‡ç»´åº¦: {self.model.get_sentence_embedding_dimension()}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # å›é€€åˆ°æ›´å°çš„æ¨¡å‹
            print("ğŸ”„ å°è¯•åŠ è½½å¤‡ç”¨æ¨¡å‹...")
            self.model_name = "all-MiniLM-L6-v2"
            self.model = SentenceTransformer(self.model_name)
    
    def __call__(self, input: Documents) -> Embeddings:
        """
        å°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡
        
        Args:
            input: æ–‡æ¡£åˆ—è¡¨
        
        Returns:
            å‘é‡åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”Ÿæˆembedding
            embeddings = self.model.encode(input)
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼ˆChromaDBè¦æ±‚ï¼‰
            return embeddings.tolist()
            
        except Exception as e:
            print(f"âŒ Embeddingç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›é›¶å‘é‡ä½œä¸ºå¤‡ç”¨
            dim = self.model.get_sentence_embedding_dimension()
            return [[0.0] * dim] * len(input)

def query_to_vector_local(text, model_name="all-MiniLM-L6-v2"):
    """
    å•ç‹¬çš„å‘é‡è½¬æ¢å‡½æ•°ï¼Œç”¨äºæµ‹è¯•
    
    Args:
        text: è¦è½¬æ¢çš„æ–‡æœ¬
        model_name: æ¨¡å‹åç§°
    
    Returns:
        numpyæ•°ç»„æ ¼å¼çš„å‘é‡
    """
    if not SENTENCE_TRANSFORMERS_AVAILABLE:
        print("âŒ éœ€è¦å®‰è£…sentence-transformers")
        return None
    
    try:
        model = SentenceTransformer(model_name)
        vector = model.encode([text])
        return vector[0]  # è¿”å›ç¬¬ä¸€ä¸ªç»“æœ
    except Exception as e:
        print(f"âŒ æœ¬åœ°embeddingå¤±è´¥: {e}")
        return None

# æ¨èçš„æ¨¡å‹é…ç½®
RECOMMENDED_MODELS = {
    "lightweight": {
        "name": "all-MiniLM-L6-v2",
        "description": "è½»é‡çº§ï¼Œå¿«é€Ÿï¼Œ384ç»´ï¼Œä¸»è¦æ”¯æŒè‹±æ–‡",
        "size": "23MB"
    },
    "multilingual": {
        "name": "paraphrase-multilingual-MiniLM-L12-v2", 
        "description": "å¤šè¯­è¨€æ”¯æŒï¼Œ384ç»´ï¼Œä¸­è‹±æ–‡æ•ˆæœå¥½",
        "size": "266MB"
    },
    "best_quality": {
        "name": "all-mpnet-base-v2",
        "description": "æœ€ä½³è´¨é‡ï¼Œ768ç»´ï¼Œä¸»è¦æ”¯æŒè‹±æ–‡",
        "size": "420MB"
    }
}

def test_local_embedding():
    """æµ‹è¯•æœ¬åœ°embedding"""
    if not SENTENCE_TRANSFORMERS_AVAILABLE:
        print("âŒ è¯·å…ˆå®‰è£…: pip install sentence-transformers")
        return False
    
    print("ğŸ§ª æµ‹è¯•æœ¬åœ°Embeddingæ¨¡å‹...")
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•",
        "This is an English test",
        "RAGæŠ€æœ¯å¾ˆæœ‰ç”¨"
    ]
    
    for model_info in RECOMMENDED_MODELS.values():
        model_name = model_info["name"]
        print(f"\nğŸ“Š æµ‹è¯•æ¨¡å‹: {model_name}")
        print(f"   æè¿°: {model_info['description']}")
        print(f"   å¤§å°: {model_info['size']}")
        
        try:
            # æµ‹è¯•å•ä¸ªæ–‡æœ¬
            vector = query_to_vector_local(test_texts[0], model_name)
            if vector is not None:
                print(f"   âœ… æˆåŠŸ! å‘é‡ç»´åº¦: {vector.shape}")
                print(f"   å‰5ä¸ªå€¼: {vector[:5]}")
                break
            else:
                print(f"   âŒ å¤±è´¥")
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}")
    
    return True

if __name__ == '__main__':
    print("ğŸ  æœ¬åœ°Embeddingæ¨¡å‹æµ‹è¯•")
    print("="*40)
    
    success = test_local_embedding()
    
    if success:
        print("\nğŸ‰ æœ¬åœ°embeddingè®¾ç½®æˆåŠŸ!")
        print("ç°åœ¨å¯ä»¥åœ¨RAGç³»ç»Ÿä¸­ä½¿ç”¨æœ¬åœ°embeddingäº†")
        print("\nğŸ“‹ å®‰è£…å‘½ä»¤:")
        print("pip install sentence-transformers")
    else:
        print("\nğŸ’¡ å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥å°è¯•:")
        print("1. pip install sentence-transformers torch")
        print("2. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰") 