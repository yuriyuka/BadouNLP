# -*- coding: utf-8 -*-
# coding: utf-8
# @Time        : 2025/5/28
# @Author      : liuboyuan
# @Description : ä½¿ç”¨RNNè¿›è¡Œå­—ç¬¦ä¸²ä¸­å­—ç¬¦'a'ä½ç½®åˆ†ç±»ä»»åŠ¡

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
import string
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score
from classifier_ import TorchModel

class StringDataset(Dataset):
    def __init__(self, strings, labels, vocab):
        self.strings = strings
        self.labels = labels
        self.vocab = vocab
        
    def __len__(self):
        return len(self.strings)
    
    def __getitem__(self, idx):
        string = self.strings[idx]
        label = self.labels[idx]
        
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºç´¢å¼•
        indices = [self.vocab.get(char, self.vocab['<UNK>']) for char in string]
        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)

def build_vocab(strings):
    """æ„å»ºè¯æ±‡è¡¨"""
    vocab = {'<PAD>': 0, '<UNK>': 1}
    for string in strings:
        for char in string:
            if char not in vocab:
                vocab[char] = len(vocab)
    return vocab

def generate_sample_data(max_length=10):
    """ç”Ÿæˆå•ä¸ªæ ·æœ¬ï¼šåŒ…å«å­—ç¬¦'a'çš„éšæœºå­—ç¬¦ä¸²"""
    # éšæœºé€‰æ‹©å­—ç¬¦ä¸²é•¿åº¦ï¼ˆè‡³å°‘ä¸º1ï¼‰
    length = random.randint(1, max_length)
    
    # éšæœºé€‰æ‹©'a'ç¬¬ä¸€æ¬¡å‡ºç°çš„ä½ç½®
    a_position = random.randint(0, length - 1)
    
    # ç”Ÿæˆå­—ç¬¦ä¸²
    chars = []
    for i in range(length):
        if i == a_position:
            chars.append('a')
        elif i > a_position:
            # 'a'å‡ºç°åï¼Œå¯ä»¥éšæœºé€‰æ‹©ä»»æ„å­—ç¬¦ï¼ˆåŒ…æ‹¬'a'ï¼‰
            chars.append(random.choice(string.ascii_lowercase))
        else:
            # 'a'å‡ºç°å‰ï¼Œä¸èƒ½åŒ…å«'a'
            chars.append(random.choice([c for c in string.ascii_lowercase if c != 'a']))
    
    return ''.join(chars), a_position

def build_dataset(sample_count, max_length=10):
    """æ„å»ºæ•°æ®é›†"""
    strings = []
    labels = []
    
    for _ in range(sample_count):
        string, label = generate_sample_data(max_length)
        strings.append(string)
        labels.append(label)
    
    return strings, labels

def pad_sequences(sequences, max_length, pad_value=0):
    """å¡«å……åºåˆ—åˆ°ç»Ÿä¸€é•¿åº¦"""
    padded = []
    for seq in sequences:
        if len(seq) < max_length:
            padded.append(seq + [pad_value] * (max_length - len(seq)))
        else:
            padded.append(seq[:max_length])
    return torch.tensor(padded, dtype=torch.long)

def collate_fn(batch):
    """è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°"""
    sequences, labels = zip(*batch)
    
    # æ‰¾åˆ°æ‰¹æ¬¡ä¸­çš„æœ€å¤§é•¿åº¦
    max_length = max(len(seq) for seq in sequences)
    
    # å¡«å……åºåˆ—
    padded_sequences = []
    for seq in sequences:
        if len(seq) < max_length:
            padded_seq = torch.cat([seq, torch.zeros(max_length - len(seq), dtype=torch.long)])
        else:
            padded_seq = seq
        padded_sequences.append(padded_seq)
    
    return torch.stack(padded_sequences), torch.stack(labels)

def train_model(model, train_loader, optimizer, device):
    """è®­ç»ƒæ¨¡å‹ä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    all_predictions = []
    all_labels = []
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        loss = model(data, target)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        # è·å–é¢„æµ‹ç»“æœ
        with torch.no_grad():
            predictions = model(data)
            predicted_classes = torch.argmax(predictions, dim=1)
            all_predictions.extend(predicted_classes.cpu().numpy())
            all_labels.extend(target.cpu().numpy())
    
    avg_loss = total_loss / len(train_loader)
    accuracy = accuracy_score(all_labels, all_predictions)
    
    return avg_loss, accuracy

def evaluate_model(model, test_loader, device):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            predictions = model(data)
            predicted_classes = torch.argmax(predictions, dim=1)
            
            all_predictions.extend(predicted_classes.cpu().numpy())
            all_labels.extend(target.cpu().numpy())
    
    accuracy = accuracy_score(all_labels, all_predictions)
    return accuracy

def plot_metrics(train_losses, train_accuracies):
    """ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡"""
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses)
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    
    plt.subplot(1, 2, 2)
    plt.plot(train_accuracies)
    plt.title('Training Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    
    plt.tight_layout()
    plt.show()

def predict_samples(model, test_strings, vocab, device, max_length=10):
    """å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹"""
    model.eval()
    predictions = []
    
    with torch.no_grad():
        for string in test_strings:
            # è½¬æ¢ä¸ºç´¢å¼•
            indices = [vocab.get(char, vocab['<UNK>']) for char in string]
            
            # å¡«å……æˆ–æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦
            if len(indices) < max_length:
                indices.extend([vocab['<PAD>']] * (max_length - len(indices)))
            else:
                indices = indices[:max_length]
            
            # è½¬æ¢ä¸ºtensorå¹¶æ·»åŠ batchç»´åº¦
            input_tensor = torch.tensor([indices], dtype=torch.long).to(device)
            
            # é¢„æµ‹
            output = model(input_tensor)
            predicted_class = torch.argmax(output, dim=1).item()
            predictions.append(predicted_class)
    
    return predictions

def main():
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è¶…å‚æ•°è®¾ç½®
    max_length = 10
    train_sample_count = 5000
    test_sample_count = 1000
    batch_size = 32
    epochs = 20
    learning_rate = 0.001
    vector_dim = 64
    hidden_dim = 128
    
    print("ğŸ“Š å¼€å§‹æ„å»ºæ•°æ®é›†...")
    
    # æ„å»ºè®­ç»ƒæ•°æ®é›†
    train_strings, train_labels = build_dataset(train_sample_count, max_length)
    
    # æ„å»ºæµ‹è¯•æ•°æ®é›†
    test_strings, test_labels = build_dataset(test_sample_count, max_length)
    
    # æ„å»ºè¯æ±‡è¡¨
    all_strings = train_strings + test_strings
    vocab = build_vocab(all_strings)
    print(f"è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
    print(f"è¯æ±‡è¡¨: {vocab}")
    
    # è®¡ç®—ç±»åˆ«æ•°ï¼ˆæœ€å¤§ä½ç½®ç´¢å¼• + 1ï¼‰
    num_classes = max_length
    print(f"åˆ†ç±»ç±»åˆ«æ•°: {num_classes}")
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = StringDataset(train_strings, train_labels, vocab)
    test_dataset = StringDataset(test_strings, test_labels, vocab)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)
    
    # åˆ›å»ºæ¨¡å‹
    model = TorchModel(vector_dim, num_classes, vocab, hidden_dim).to(device)
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    train_losses = []
    train_accuracies = []
    
    for epoch in range(epochs):
        train_loss, train_acc = train_model(model, train_loader, optimizer, device)
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        
        if (epoch + 1) % 5 == 0:
            print(f"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}")
    
    # è¯„ä¼°æ¨¡å‹
    test_accuracy = evaluate_model(model, test_loader, device)
    print(f"ğŸ¯ æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f}")
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_metrics(train_losses, train_accuracies)
    
    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), 'rnn_classifier_model.pth')
    print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º rnn_classifier_model.pth")
    
    # æµ‹è¯•é¢„æµ‹åŠŸèƒ½
    print("\nğŸ”® å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹:")
    test_samples = [
        "abcdef",     # 'a'åœ¨ä½ç½®0
        "bcadef",     # 'a'åœ¨ä½ç½®2
        "bcdaef",     # 'a'åœ¨ä½ç½®3
        "bcdefga",    # 'a'åœ¨ä½ç½®6
        "a",          # åªæœ‰'a'ï¼Œåœ¨ä½ç½®0
    ]
    
    predictions = predict_samples(model, test_samples, vocab, device, max_length)
    
    for i, (sample, pred) in enumerate(zip(test_samples, predictions)):
        actual_pos = sample.index('a') if 'a' in sample else -1
        print(f"æ ·æœ¬ {i+1}: '{sample}' â†’ é¢„æµ‹ä½ç½®: {pred}, å®é™…ä½ç½®: {actual_pos}")

if __name__ == "__main__":
    main() 