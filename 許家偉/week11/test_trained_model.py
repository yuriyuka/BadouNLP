# -*- coding: utf-8 -*-
import torch
import json
import logging
from config import Config
from transformer.Models import Transformer
from transformer.Translator import Translator

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ModelTester:
    def __init__(self, model_path, config):
        self.config = config
        self.model_path = model_path
        
        # åŠ è¼‰è©å½™è¡¨
        self.vocab = self.load_vocab(config["vocab_path"])
        self.reverse_vocab = {v: k for k, v in self.vocab.items()}
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = Transformer(
            n_src_vocab=config["vocab_size"], 
            n_trg_vocab=config["vocab_size"], 
            src_pad_idx=0, 
            trg_pad_idx=0,
            d_word_vec=128, 
            d_model=128, 
            d_inner=256,
            n_layers=1, 
            n_head=2, 
            d_k=64, 
            d_v=64
        )
        
        # åŠ è¼‰è¨“ç·´å¥½çš„æ¨¡å‹æ¬Šé‡
        self.model.load_state_dict(torch.load(model_path, map_location='cpu'))
        self.model.eval()
        
        # åˆå§‹åŒ–ç¿»è­¯å™¨
        self.translator = Translator(
            self.model,
            config["beam_size"],
            config["output_max_length"],
            config["pad_idx"],
            config["pad_idx"],
            config["start_idx"],
            config["end_idx"]
        )
        
        logger.info("æ¨¡å‹åŠ è¼‰å®Œæˆï¼")
    
    def load_vocab(self, vocab_path):
        """åŠ è¼‰è©å½™è¡¨"""
        token_dict = {}
        with open(vocab_path, encoding="utf8") as f:
            for index, line in enumerate(f):
                token = line.strip()
                token_dict[token] = index
        return token_dict
    
    def encode_sentence(self, text, max_length):
        """å°‡æ–‡æœ¬ç·¨ç¢¼ç‚ºåºåˆ—"""
        input_id = []
        for char in text:
            input_id.append(self.vocab.get(char, self.vocab["[UNK]"]))
        
        # å¡«å……æˆ–æˆªæ–·
        input_id = input_id[:max_length]
        input_id += [self.vocab["[PAD]"]] * (max_length - len(input_id))
        return torch.LongTensor(input_id)
    
    def decode_seq(self, seq):
        """å°‡åºåˆ—è§£ç¢¼ç‚ºæ–‡æœ¬"""
        return "".join([self.reverse_vocab[int(idx)] for idx in seq if int(idx) not in [self.vocab["[PAD]"], self.vocab["[CLS]"], self.vocab["[SEP]"]]])
    
    def test_single_input(self, input_text):
        """æ¸¬è©¦å–®å€‹è¼¸å…¥"""
        print(f"\n{'='*60}")
        print(f"è¼¸å…¥æ–‡æœ¬: {input_text}")
        print(f"{'='*60}")
        
        # ç·¨ç¢¼è¼¸å…¥
        input_seq = self.encode_sentence(input_text, self.config["input_max_length"])
        
        # ç”Ÿæˆè¼¸å‡º
        with torch.no_grad():
            generated = self.translator.translate_sentence(input_seq.unsqueeze(0))
        
        # è§£ç¢¼è¼¸å‡º
        output_text = self.decode_seq(generated)
        
        print(f"ç”Ÿæˆçµæœ: {output_text}")
        print(f"{'='*60}")
        
        return output_text
    
    def test_multiple_inputs(self, test_cases):
        """æ¸¬è©¦å¤šå€‹è¼¸å…¥"""
        print(f"\né–‹å§‹æ¸¬è©¦ {len(test_cases)} å€‹æ¨£æœ¬...")
        print(f"{'='*80}")
        
        results = []
        for i, (input_text, expected_output) in enumerate(test_cases, 1):
            print(f"\næ¸¬è©¦æ¡ˆä¾‹ {i}:")
            generated = self.test_single_input(input_text)
            results.append({
                'input': input_text,
                'expected': expected_output,
                'generated': generated
            })
        
        return results
    
    def test_with_sample_data(self, num_samples=5):
        """ä½¿ç”¨åŸå§‹æ•¸æ“šé€²è¡Œæ¸¬è©¦"""
        print(f"\nä½¿ç”¨åŸå§‹æ•¸æ“šæ¸¬è©¦ {num_samples} å€‹æ¨£æœ¬...")
        print(f"{'='*80}")
        
        # è®€å–åŸå§‹æ•¸æ“š
        test_cases = []
        with open(self.config["train_data_path"], 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= num_samples:
                    break
                data = json.loads(line.strip())
                test_cases.append((data["answer"], data["question"]))
        
        return self.test_multiple_inputs(test_cases)

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    model_path = "output/epoch_300.pth"
    
    try:
        # åˆå§‹åŒ–æ¸¬è©¦å™¨
        tester = ModelTester(model_path, Config)
        
        # æ¸¬è©¦1: è‡ªå®šç¾©è¼¸å…¥
        print("ğŸ§ª æ¸¬è©¦1: è‡ªå®šç¾©è¼¸å…¥")
        custom_tests = [
            ("ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œé™½å…‰æ˜åªšï¼Œé©åˆå‡ºé–€æ•£æ­¥ã€‚", "å¤©æ°£"),
            ("åŒ—äº¬æ•…å®®æ˜¯ä¸­åœ‹å¤ä»£å®®æ®¿å»ºç¯‰çš„ä»£è¡¨ï¼Œå…·æœ‰é‡è¦çš„æ­·å²æ–‡åŒ–åƒ¹å€¼ã€‚", "æ•…å®®"),
            ("äººå·¥æ™ºèƒ½æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œæ”¹è®Šè‘—æˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ã€‚", "AI"),
            ("ç’°ä¿å•é¡Œæ—¥ç›Šåš´é‡ï¼Œæˆ‘å€‘éœ€è¦å…±åŒåŠªåŠ›ä¿è­·åœ°çƒã€‚", "ç’°ä¿"),
            ("æ•™è‚²æ˜¯åœ‹å®¶ç™¼å±•çš„åŸºç¤ï¼Œæ‡‰è©²é‡è¦–æ•™è‚²äº‹æ¥­çš„ç™¼å±•ã€‚", "æ•™è‚²")
        ]
        
        results1 = tester.test_multiple_inputs(custom_tests)
        
        # æ¸¬è©¦2: ä½¿ç”¨åŸå§‹æ•¸æ“š
        print("\nğŸ§ª æ¸¬è©¦2: ä½¿ç”¨åŸå§‹è¨“ç·´æ•¸æ“š")
        results2 = tester.test_with_sample_data(num_samples=3)
        
        # ç¸½çµ
        print(f"\n{'='*80}")
        print("ğŸ‰ æ¸¬è©¦å®Œæˆï¼")
        print(f"{'='*80}")
        print("æ¨¡å‹èƒ½å¤ æ ¹æ“šè¼¸å…¥æ–‡æœ¬ç”Ÿæˆç›¸é—œçš„æ¨™é¡Œ/æ‘˜è¦ã€‚")
        print("é›–ç„¶ç”Ÿæˆçš„æ–‡æœ¬å¯èƒ½é‚„ä¸å¤ å®Œç¾ï¼Œä½†å·²ç¶“é¡¯ç¤ºå‡ºå­¸ç¿’æ•ˆæœã€‚")
        
    except Exception as e:
        logger.error(f"æ¸¬è©¦éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 