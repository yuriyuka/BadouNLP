from transformers import BertTokenizer, BertForQuestionAnswering, pipeline
import torch
import re
import random


class CompleteDialogueSystem:
    def __init__(self):
        # åˆå§‹åŒ–é—®ç­”æ¨¡å‹
        self.qa_tokenizer = BertTokenizer.from_pretrained("bert-base-cased")
        self.qa_model = BertForQuestionAnswering.from_pretrained("bert-base-cased")

        # åˆå§‹åŒ–å¯¹è¯æ¨¡å‹ï¼ˆç”¨äºé—²èŠï¼‰
        self.chatbot = pipeline(
            "text-generation",
            model="microsoft/DialoGPT-medium",
            tokenizer="microsoft/DialoGPT-medium"
        )

        self.conversation_history = []
        self.current_context = ""
        self.last_qa_answer = ""

    def set_context(self, context):
        """è®¾ç½®å¯¹è¯ä¸Šä¸‹æ–‡"""
        self.current_context = context
        print(f"å·²è®¾ç½®ä¸Šä¸‹æ–‡ï¼š{context[:100]}...")

    def extract_answer(self, question):
        """ä»ä¸Šä¸‹æ–‡ä¸­æå–ç­”æ¡ˆ"""
        try:
            inputs = self.qa_tokenizer(question, self.current_context, return_tensors="pt", truncation=True,
                                       max_length=512)

            with torch.no_grad():
                outputs = self.qa_model(**inputs)

            start_scores = outputs.start_logits
            end_scores = outputs.end_logits

            start_idx = torch.argmax(start_scores)
            end_idx = torch.argmax(end_scores)

            answer_tokens = inputs["input_ids"][0][start_idx:end_idx + 1]
            answer = self.qa_tokenizer.decode(answer_tokens, skip_special_tokens=True)

            return answer.strip()
        except:
            return None

    def chat_response(self, user_input):
        """ç”Ÿæˆé—²èŠå›å¤"""
        # æ„å»ºå¯¹è¯å†å²
        chat_history = ""
        for msg in self.conversation_history[-4:]:  # æœ€è¿‘4æ¡æ¶ˆæ¯
            if msg['role'] == 'user':
                chat_history += f"ç”¨æˆ·ï¼š{msg['content']}\n"
            else:
                chat_history += f"åŠ©æ‰‹ï¼š{msg['content']}\n"

        prompt = f"{chat_history}ç”¨æˆ·ï¼š{user_input}\nåŠ©æ‰‹ï¼š"

        try:
            response = self.chatbot(
                prompt,
                max_length=200,
                num_return_sequences=1,
                temperature=0.7,
                do_sample=True
            )[0]['generated_text']

            # æå–åŠ©æ‰‹çš„å›å¤
            assistant_response = response.split("åŠ©æ‰‹ï¼š")[-1].strip()
            return assistant_response
        except:
            # å¦‚æœæ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨é¢„è®¾å›å¤
            return self.get_fallback_response(user_input)

    def get_fallback_response(self, user_input):
        """é¢„è®¾å›å¤"""
        greetings = ["ä½ å¥½ï¼", "å—¨ï¼", "æ‚¨å¥½ï¼", "å¾ˆé«˜å…´å’Œæ‚¨èŠå¤©ï¼"]
        questions = ["å¾ˆæœ‰è¶£çš„é—®é¢˜ï¼", "è®©æˆ‘æƒ³æƒ³...", "è¿™æ˜¯ä¸ªå¥½é—®é¢˜ï¼"]
        unknowns = ["æˆ‘ä¸å¤ªæ˜ç™½ï¼Œèƒ½æ¢ä¸ªè¯´æ³•å—ï¼Ÿ", "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç¡®å®šæ‚¨çš„æ„æ€", "èƒ½å†è¯´å¾—è¯¦ç»†äº›å—ï¼Ÿ"]

        user_input = user_input.lower()

        if any(word in user_input for word in ["ä½ å¥½", "å—¨", "hello", "hi"]):
            return random.choice(greetings)
        elif any(word in user_input for word in ["å—ï¼Ÿ", "å—", "ï¼Ÿ", "?"]):
            return random.choice(questions)
        else:
            return random.choice(unknowns)

    def is_repeat_request(self, user_input):
        """æ£€æµ‹é‡å¤è¯·æ±‚"""
        repeat_patterns = [
            r'æ²¡å¬æ‡‚', r'å†è¯´ä¸€é', r'é‡å¤', r'æ²¡å¬æ¸…',
            r'å†è¯´ä¸€æ¬¡', r'ä»€ä¹ˆ', r'pardon', r'what',
            r'åˆšåˆšè¯´ä»€ä¹ˆ', r'æ²¡å¬æ˜ç™½'
        ]

        user_input = user_input.lower()
        return any(re.search(pattern, user_input) for pattern in repeat_patterns)

    def is_qa_question(self, user_input):
        """æ£€æµ‹æ˜¯å¦æ˜¯é—®ç­”é—®é¢˜"""
        qa_keywords = ["è°", "ä»€ä¹ˆ", "å“ªé‡Œ", "ä½•æ—¶", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "å¦‚ä½•", "who", "what", "where", "when", "why",
                       "how"]
        user_input = user_input.lower()
        return any(keyword in user_input for keyword in qa_keywords) and "ï¼Ÿ" in user_input or "?" in user_input

    def process_message(self, user_input):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        user_input = user_input.strip()

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        self.conversation_history.append({"role": "user", "content": user_input})

        # æ£€æŸ¥é‡å¤è¯·æ±‚
        if self.is_repeat_request(user_input) and self.last_qa_answer:
            response = f"å¥½çš„ï¼Œæˆ‘å†è¯´ä¸€éï¼š{self.last_qa_answer}"
            self.conversation_history.append({"role": "assistant", "content": response})
            return response

        # æ£€æŸ¥æ˜¯å¦æ˜¯é—®ç­”é—®é¢˜ä¸”æœ‰ä¸Šä¸‹æ–‡
        if self.is_qa_question(user_input) and self.current_context:
            answer = self.extract_answer(user_input)
            if answer and len(answer) > 2:  # ç¡®ä¿ç­”æ¡ˆæœ‰æ•ˆ
                self.last_qa_answer = answer
                response = f"æ ¹æ®ä¸Šä¸‹æ–‡ï¼š{answer}"
            else:
                response = "æŠ±æ­‰ï¼Œæˆ‘åœ¨ä¸Šä¸‹æ–‡ä¸­æ‰¾ä¸åˆ°è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚"
        else:
            # é—²èŠæ¨¡å¼
            response = self.chat_response(user_input)

        # ä¿å­˜åŠ©æ‰‹å›å¤
        self.conversation_history.append({"role": "assistant", "content": response})
        return response


# å¢å¼ºç‰ˆå¯¹è¯ç•Œé¢
def run_enhanced_chat():
    system = CompleteDialogueSystem()

    print("=" * 50)
    print("ğŸ¤– æ™ºèƒ½å¯¹è¯æœºå™¨äººå·²å¯åŠ¨ï¼")
    print("ğŸ“ åŠŸèƒ½ï¼š")
    print("  - é—®ç­”ï¼šåŸºäºä¸Šä¸‹æ–‡å›ç­”è°ã€ä»€ä¹ˆã€å“ªé‡Œç­‰é—®é¢˜")
    print("  - é—²èŠï¼šæ™®é€šå¯¹è¯äº¤æµ")
    print("  - é‡å¬ï¼šè¯´'æ²¡å¬æ‡‚'å¯ä»¥é‡å¤ä¸Šä¸€ä¸ªç­”æ¡ˆ")
    print("  - è¾“å…¥'è®¾ç½®ä¸Šä¸‹æ–‡'æ¥è®¾ç½®é—®ç­”èƒŒæ™¯")
    print("  - è¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯")
    print("=" * 50)

    # åˆå§‹ä¸Šä¸‹æ–‡è®¾ç½®
    initial_context = """
    Jim Hensonæ˜¯ä¸€ä½ç¾å›½æœ¨å¶å¸ˆã€åŠ¨ç”»å¸ˆã€æ¼«ç”»å®¶ã€æ¼”å‘˜ã€å‘æ˜å®¶å’Œç”µå½±åˆ¶ç‰‡äººï¼Œå› åˆ›ä½œã€Šå¸ƒå¶ç§€ã€‹è€Œäº«èª‰å…¨çƒã€‚
    ä»–äº1936å¹´å‡ºç”Ÿï¼Œ1990å¹´å»ä¸–ã€‚äº¨æ£®åˆ›é€ äº†è‘—åçš„è§’è‰²å¦‚é’è›™å…‹ç±³ç‰¹ã€çŒªå°å§å’Œå¤§é¸Ÿã€‚
    ä»–çš„ä½œå“å¯¹å„¿ç«¥ç”µè§†èŠ‚ç›®äº§ç”Ÿäº†æ·±è¿œå½±å“ï¼Œå¹¶è·å¾—äº†å¤šä¸ªè‰¾ç¾å¥–ã€‚
    """
    system.set_context(initial_context)

    while True:
        try:
            user_input = input("\nğŸ‘¤ æ‚¨ï¼š").strip()

            if user_input.lower() in ['é€€å‡º', 'exit', 'quit', 'bye']:
                print("ğŸ¤– æœºå™¨äººï¼šå†è§ï¼å¾ˆé«˜å…´å’Œæ‚¨èŠå¤©ï¼")
                break

            elif user_input.lower() in ['è®¾ç½®ä¸Šä¸‹æ–‡', 'set context']:
                new_context = input("è¯·è¾“å…¥æ–°çš„ä¸Šä¸‹æ–‡ï¼š")
                system.set_context(new_context)
                print("ğŸ¤– æœºå™¨äººï¼šä¸Šä¸‹æ–‡å·²æ›´æ–°ï¼")
                continue

            elif not user_input:
                print("ğŸ¤– æœºå™¨äººï¼šè¯·è¯´ç‚¹ä»€ä¹ˆå§~")
                continue

            # å¤„ç†ç”¨æˆ·è¾“å…¥
            response = system.process_message(user_input)
            print(f"ğŸ¤– æœºå™¨äººï¼š{response}")

        except KeyboardInterrupt:
            print("\nğŸ¤– æœºå™¨äººï¼šæ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"ğŸ¤– æœºå™¨äººï¼šå‡ºé”™äº†ï¼Œè¯·é‡æ–°è¾“å…¥ ({str(e)})")


# å¿«é€Ÿæµ‹è¯•
def quick_test():
    system = CompleteDialogueSystem()

    # è®¾ç½®æµ‹è¯•ä¸Šä¸‹æ–‡
    context = """
    æ¸…åå¤§å­¦æ˜¯ä¸­å›½è‘—åçš„ç»¼åˆæ€§å¤§å­¦ï¼Œä½äºåŒ—äº¬å¸‚ã€‚æˆç«‹äº1911å¹´ï¼Œæ˜¯ä¸­å›½æœ€é¡¶å°–çš„é«˜ç­‰å­¦åºœä¹‹ä¸€ã€‚
    æ¸…åå¤§å­¦åœ¨å·¥ç¨‹ã€è®¡ç®—æœºç§‘å­¦ã€ç»æµç®¡ç†ç­‰é¢†åŸŸäº«æœ‰ç››èª‰ã€‚æ ¡å›­å åœ°é¢ç§¯çº¦400å…¬é¡·ï¼Œé£æ™¯ä¼˜ç¾ã€‚
    """
    system.set_context(context)

    test_cases = [
        "ä½ å¥½ï¼",
        "æ¸…åå¤§å­¦åœ¨å“ªé‡Œï¼Ÿ",
        "æ²¡å¬æ‡‚ï¼Œå†è¯´ä¸€é",
        "æ¸…åå¤§å­¦æˆç«‹äºå“ªä¸€å¹´ï¼Ÿ",
        "ä»Šå¤©å¤©æ°”çœŸå¥½",
        "æ¸…åå¤§å­¦ä»¥ä»€ä¹ˆä¸“ä¸šé—»åï¼Ÿ",
        "å†è§"
    ]

    for test in test_cases:
        print(f"\nğŸ‘¤ æµ‹è¯•è¾“å…¥ï¼š{test}")
        response = system.process_message(test)
        print(f"ğŸ¤– å›å¤ï¼š{response}")


if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´å¯¹è¯ç³»ç»Ÿ
    # run_enhanced_chat()

    # æˆ–è€…è¿è¡Œå¿«é€Ÿæµ‹è¯•
    quick_test()
