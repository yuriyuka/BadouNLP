text = ('''
 BPE æœ€åˆæ˜¯ä¸€ç§æ•°æ®å‹ç¼©ç®—æ³•ï¼Œé€šè¿‡è¿­ä»£åˆå¹¶æ•°æ®ä¸­æœ€é¢‘ç¹å‡ºç°çš„å­—èŠ‚å¯¹ï¼ˆByte Pairï¼‰ï¼Œé€æ­¥æ„å»ºä¸€ä¸ªç¼–ç è¡¨ï¼Œå°†é«˜é¢‘å­—èŠ‚å¯¹æ›¿æ¢ä¸ºä¸€ä¸ªæ–°çš„ç¬¦å·ï¼Œä»è€Œå‡å°‘æ•°æ®ä¸­çš„é‡å¤æ¨¡å¼ï¼Œè¾¾åˆ°å‹ç¼©ç›®çš„ã€‚å…¶æ ¸å¿ƒé€»è¾‘æ˜¯ï¼šé€šè¿‡ç»Ÿè®¡æ•°æ®ä¸­ç›¸é‚»ç¬¦å·çš„é¢‘ç‡ï¼Œä¸æ–­åˆå¹¶é«˜é¢‘ç¬¦å·å¯¹ï¼Œç”Ÿæˆæ›´å¤æ‚çš„æ–°ç¬¦å·ï¼Œæœ€ç»ˆå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºç¬¦å·åºåˆ—ï¼Œå‡å°‘æ•°æ®å†—ä½™ã€‚
 A Programmerâ€™s Introduction to Unicode March 3, 2017 Â· Coding Â· 22 Comments  ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡º\u200cğŸ‡³\u200cğŸ‡®\u200cğŸ‡¨\u200cğŸ‡´\u200cğŸ‡©\u200cğŸ‡ª! ğŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.  A few months ago, I got interested in Unicode and decided to spend some time learning more about it in detail.
''')

tokens = text.encode("utf-8")
tokens = list(map(int,tokens))

def get_stats(ids):
    counts ={}
    for pair in zip(ids,ids[1:]):
        counts [pair] = counts.get(pair,0) + 1
    return counts
def merge(ids,pair,idx):
    newids =[]
    i = 0
    while i < len(ids):
        if i< len(ids) -1 and ids[i] == pair[0] and ids[i+1] == pair[1]:
            newids.append(idx)
            i +=2
        else:
            newids.append(ids[i])
            i += 1
    return newids

vocab_size = 276
num_merges = vocab_size -256
ids = list(tokens)

merges = {}
for i in range(num_merges):
    stats = get_stats(ids)
    pair = max(stats,key = stats.get)
    idx = 256 + i
    print(f"mergeing {pair} into a new token {idx}")
    ids = merge(ids,pair,idx)
    merges[pair] = idx

print("tokens length:",len(tokens))
print("ids length:",len(ids))
print(f"compression ratio: {len(tokens)/len(ids):.2f}X")

print("=====================================================")

vocab = {idx: bytes([idx])for idx in  range(256)}
for(p0,p1) ,idx in merges.items():
    vocab[idx] = vocab[p0] + vocab[p1]

def decode(ids):
    tokens = b"".join(vocab[idx] for idx in ids)
    text = tokens.decode("utf-8",errors = "replace")
    return text

print("decode ç¤ºä¾‹:",decode(
[65, 32, 80, 114, 111, 103, 114, 97, 109, 109, 260, 263, 153, 258, 73, 110, 116, 114, 111, 100, 117, 99, 116, 105,
     111, 110, 32, 116, 111, 32, 85, 110, 105, 271, 101,]
))
print("=====================================================")
print(merges)
print("=====================================================")
def encode(text):
    tokens = list(text.encode("utf-8"))
    while len(tokens)>=2:
        stats = get_stats(tokens)
        pair = min(stats,key =lambda p:merges.get(p,float("inf")))
        if pair not in merges:
            break
        idx = merges[pair]
        tokens = merge(tokens,pair,idx)
    return tokens

str ='ç­‰åˆ°é»‘å¤œåé¢ä¹‹å ä¼šæ˜¯æ–°çš„ç™½æ˜¼ ç­‰åˆ°æµ·å•¸é€€å»ä¹‹å åªæ˜¯æ½®èµ·æ½®è½'
print("encode ç¤ºä¾‹:",encode("ç­‰åˆ°é»‘å¤œåé¢ä¹‹å ä¼šæ˜¯æ–°çš„ç™½æ˜¼ ç­‰åˆ°æµ·å•¸é€€å»ä¹‹å åªæ˜¯æ½®èµ·æ½®è½"))

for i in str:
    print(i,encode(i))
print(str == decode(encode(str)))
